{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB1 - Model Operationalization & Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will create the artifacts and scripts to deploy the LSTM model into a webservice on Azure. The artifacts include the model files, and test scripts to validate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# import the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import h5py\n",
    "\n",
    "# For Azure blob storage access\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER = \"MSFT\"\n",
    "\n",
    "SHARE_ROOT = \"./stockdemo-model/\"\n",
    "\n",
    "# the model in h5 format\n",
    "LSTM_MODEL = TICKER +'-modellstm.h5'\n",
    "LSTM_MODEL_PATH = SHARE_ROOT + LSTM_MODEL\n",
    "\n",
    "# the min_max values dictionary\n",
    "MIN_MAX_DICT = TICKER +'-min_max.pkl'\n",
    "MIN_MAX_DICT_PATH = SHARE_ROOT + MIN_MAX_DICT\n",
    "\n",
    "# Azure Container Service (ACI) Name\n",
    "ACI_SERVICE_NAME = TICKER + '-aciservice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the test data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"MSFT.csv\", index_col='Date')\n",
    "# Converting the index as date\n",
    "data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>117.37</td>\n",
       "      <td>118.62</td>\n",
       "      <td>112.00</td>\n",
       "      <td>116.56</td>\n",
       "      <td>26614200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.066089</td>\n",
       "      <td>39.482146</td>\n",
       "      <td>37.278708</td>\n",
       "      <td>38.796484</td>\n",
       "      <td>53228400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>113.56</td>\n",
       "      <td>117.12</td>\n",
       "      <td>112.25</td>\n",
       "      <td>112.62</td>\n",
       "      <td>27059500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.797947</td>\n",
       "      <td>38.982878</td>\n",
       "      <td>37.361920</td>\n",
       "      <td>37.485073</td>\n",
       "      <td>54119000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>111.12</td>\n",
       "      <td>116.37</td>\n",
       "      <td>109.37</td>\n",
       "      <td>113.81</td>\n",
       "      <td>32029800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.985804</td>\n",
       "      <td>38.733244</td>\n",
       "      <td>36.403324</td>\n",
       "      <td>37.881159</td>\n",
       "      <td>64059600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>112.19</td>\n",
       "      <td>113.87</td>\n",
       "      <td>108.37</td>\n",
       "      <td>110.00</td>\n",
       "      <td>27488300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.341949</td>\n",
       "      <td>37.901130</td>\n",
       "      <td>36.070479</td>\n",
       "      <td>36.613017</td>\n",
       "      <td>54976600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>108.62</td>\n",
       "      <td>112.25</td>\n",
       "      <td>107.31</td>\n",
       "      <td>111.44</td>\n",
       "      <td>31006800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.153690</td>\n",
       "      <td>37.361920</td>\n",
       "      <td>35.717662</td>\n",
       "      <td>37.092315</td>\n",
       "      <td>62013600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close      Volume  Ex-Dividend  \\\n",
       "Date                                                                  \n",
       "2000-01-03  117.37  118.62  112.00  116.56  26614200.0          0.0   \n",
       "2000-01-04  113.56  117.12  112.25  112.62  27059500.0          0.0   \n",
       "2000-01-05  111.12  116.37  109.37  113.81  32029800.0          0.0   \n",
       "2000-01-06  112.19  113.87  108.37  110.00  27488300.0          0.0   \n",
       "2000-01-07  108.62  112.25  107.31  111.44  31006800.0          0.0   \n",
       "\n",
       "            Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
       "Date                                                                   \n",
       "2000-01-03          1.0  39.066089  39.482146  37.278708   38.796484   \n",
       "2000-01-04          1.0  37.797947  38.982878  37.361920   37.485073   \n",
       "2000-01-05          1.0  36.985804  38.733244  36.403324   37.881159   \n",
       "2000-01-06          1.0  37.341949  37.901130  36.070479   36.613017   \n",
       "2000-01-07          1.0  36.153690  37.361920  35.717662   37.092315   \n",
       "\n",
       "            Adj. Volume  \n",
       "Date                     \n",
       "2000-01-03   53228400.0  \n",
       "2000-01-04   54119000.0  \n",
       "2000-01-05   64059600.0  \n",
       "2000-01-06   54976600.0  \n",
       "2000-01-07   62013600.0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = data.iloc[-10:].drop(columns=['Adj. Open','Adj. High','Adj. Low','Adj. Volume','Adj. Close', 'Ex-Dividend', 'Split Ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-14</th>\n",
       "      <td>95.120</td>\n",
       "      <td>95.410</td>\n",
       "      <td>93.50</td>\n",
       "      <td>93.85</td>\n",
       "      <td>31576898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-15</th>\n",
       "      <td>93.530</td>\n",
       "      <td>94.580</td>\n",
       "      <td>92.83</td>\n",
       "      <td>94.18</td>\n",
       "      <td>26279014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16</th>\n",
       "      <td>94.680</td>\n",
       "      <td>95.380</td>\n",
       "      <td>93.92</td>\n",
       "      <td>94.60</td>\n",
       "      <td>47329521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-19</th>\n",
       "      <td>93.740</td>\n",
       "      <td>93.900</td>\n",
       "      <td>92.11</td>\n",
       "      <td>92.89</td>\n",
       "      <td>31752589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-20</th>\n",
       "      <td>93.050</td>\n",
       "      <td>93.770</td>\n",
       "      <td>93.00</td>\n",
       "      <td>93.13</td>\n",
       "      <td>21787780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-21</th>\n",
       "      <td>92.930</td>\n",
       "      <td>94.050</td>\n",
       "      <td>92.21</td>\n",
       "      <td>92.48</td>\n",
       "      <td>23753263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>91.265</td>\n",
       "      <td>91.750</td>\n",
       "      <td>89.66</td>\n",
       "      <td>89.79</td>\n",
       "      <td>37578166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>89.500</td>\n",
       "      <td>90.460</td>\n",
       "      <td>87.08</td>\n",
       "      <td>87.18</td>\n",
       "      <td>42159397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>90.610</td>\n",
       "      <td>94.000</td>\n",
       "      <td>90.40</td>\n",
       "      <td>93.78</td>\n",
       "      <td>55031149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>94.940</td>\n",
       "      <td>95.139</td>\n",
       "      <td>88.51</td>\n",
       "      <td>89.47</td>\n",
       "      <td>53704562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High    Low  Close      Volume\n",
       "Date                                                \n",
       "2018-03-14  95.120  95.410  93.50  93.85  31576898.0\n",
       "2018-03-15  93.530  94.580  92.83  94.18  26279014.0\n",
       "2018-03-16  94.680  95.380  93.92  94.60  47329521.0\n",
       "2018-03-19  93.740  93.900  92.11  92.89  31752589.0\n",
       "2018-03-20  93.050  93.770  93.00  93.13  21787780.0\n",
       "2018-03-21  92.930  94.050  92.21  92.48  23753263.0\n",
       "2018-03-22  91.265  91.750  89.66  89.79  37578166.0\n",
       "2018-03-23  89.500  90.460  87.08  87.18  42159397.0\n",
       "2018-03-26  90.610  94.000  90.40  93.78  55031149.0\n",
       "2018-03-27  94.940  95.139  88.51  89.47  53704562.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Test Dataset as pickle for later use\n",
    "# the test data in pkl format\n",
    "TEST_DATA_PATH = SHARE_ROOT + 'test_dataframe.pkl'\n",
    "test_df.to_pickle(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to recreate the feature engineering (creating the sequence features) just as we did in the model building notebook.\n",
    "\n",
    "We will do this within the webservice so that the service can take the raw  data, and return a scored result predicting the value (label).\n",
    "\n",
    "When scoreing an unseen observation, the model will not know the true labels. Therefore, we create a score_df without labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test init() and run() functions to read from the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web service requires two functions, an init() function that will initialize the web service by loading the model into the service, and a run() function that will engineer the features to match the model call structure, and score that data set. We create the functions in here for testing and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    # read in the model file\n",
    "    global model\n",
    "    global min_max_dict_list\n",
    "    \n",
    "    # load model\n",
    "    model = load_model(LSTM_MODEL_PATH)\n",
    "    print(\"Model Loaded\")\n",
    "    \n",
    "    # Load Min Max list values\n",
    "    with open(MIN_MAX_DICT_PATH, 'rb') as handle:\n",
    "        min_max_dict_list = pickle.load(handle)\n",
    "        print(\"Min_max List loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = pd.read_json(data, orient='records')\n",
    "        data_n = data.copy()\n",
    "        \n",
    "        # Normalize data\n",
    "        min_dict = min_max_dict_list[0]\n",
    "        max_dict = min_max_dict_list[1]\n",
    "        for feature_name in data.columns:\n",
    "            data_n[feature_name] = (data[feature_name] - min_dict[feature_name]) / (max_dict[feature_name] - min_dict[feature_name])\n",
    "        \n",
    "        # Create sequences\n",
    "        data = data_n.values \n",
    "        seq_len = 10\n",
    "        result = []\n",
    "        for index in range(len(data) - seq_len + 1):\n",
    "            result.append(data[index: index + seq_len + 1])\n",
    "\n",
    "        result = np.array(result)\n",
    "        print(result.shape)\n",
    "        \n",
    "        pred = model.predict(result)\n",
    "        print(pred)\n",
    "        \n",
    "        # de-normalize the target\n",
    "        pred = pred * (max_dict[\"Close\"] - min_dict[\"Close\"]) + min_dict[\"Close\"]\n",
    "        \n",
    "        # Send results\n",
    "        pred = pred.tolist()\n",
    "        return json.dumps({\"result\": pred})\n",
    "\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The webservice test requires an initialize of the webservice, then send the entire scoring data set into the model. We expect to get 1  prediction for each input in the scoring data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": \"[{\\\\\"Open\\\\\":95.12,\\\\\"High\\\\\":95.41,\\\\\"Low\\\\\":93.5,\\\\\"Close\\\\\":93.85,\\\\\"Volume\\\\\":31576898.0},{\\\\\"Open\\\\\":93.53,\\\\\"High\\\\\":94.58,\\\\\"Low\\\\\":92.83,\\\\\"Close\\\\\":94.18,\\\\\"Volume\\\\\":26279014.0},{\\\\\"Open\\\\\":94.68,\\\\\"High\\\\\":95.38,\\\\\"Low\\\\\":93.92,\\\\\"Close\\\\\":94.6,\\\\\"Volume\\\\\":47329521.0},{\\\\\"Open\\\\\":93.74,\\\\\"High\\\\\":93.9,\\\\\"Low\\\\\":92.11,\\\\\"Close\\\\\":92.89,\\\\\"Volume\\\\\":31752589.0},{\\\\\"Open\\\\\":93.05,\\\\\"High\\\\\":93.77,\\\\\"Low\\\\\":93.0,\\\\\"Close\\\\\":93.13,\\\\\"Volume\\\\\":21787780.0},{\\\\\"Open\\\\\":92.93,\\\\\"High\\\\\":94.05,\\\\\"Low\\\\\":92.21,\\\\\"Close\\\\\":92.48,\\\\\"Volume\\\\\":23753263.0},{\\\\\"Open\\\\\":91.265,\\\\\"High\\\\\":91.75,\\\\\"Low\\\\\":89.66,\\\\\"Close\\\\\":89.79,\\\\\"Volume\\\\\":37578166.0},{\\\\\"Open\\\\\":89.5,\\\\\"High\\\\\":90.46,\\\\\"Low\\\\\":87.08,\\\\\"Close\\\\\":87.18,\\\\\"Volume\\\\\":42159397.0},{\\\\\"Open\\\\\":90.61,\\\\\"High\\\\\":94.0,\\\\\"Low\\\\\":90.4,\\\\\"Close\\\\\":93.78,\\\\\"Volume\\\\\":55031149.0},{\\\\\"Open\\\\\":94.94,\\\\\"High\\\\\":95.139,\\\\\"Low\\\\\":88.51,\\\\\"Close\\\\\":89.47,\\\\\"Volume\\\\\":53704562.0}]\"}'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps({\"data\": test_df.to_json(orient='records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n",
      "Min_max List loaded\n",
      "(1, 10, 5)\n",
      "[[0.7519344]]\n",
      "{\"result\": [[91.40367126464844]]}\n"
     ]
    }
   ],
   "source": [
    "init()\n",
    "pred=run(json.dumps({\"data\": test_df.to_json(orient='records')}))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we persist the assets we have created for use in operationalization. The conda dependencies are defined in this YAML file. This will be used to tell the webservice server which python packages are required to run this web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/myenv.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}myenv.yml\n",
    "name: myenv\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.5.2\n",
    "  - pip:\n",
    "    - keras\n",
    "    - tensorflow\n",
    "    - h5py\n",
    "    # Required packages for AzureML execution, history, and data preparation.\n",
    "    - --extra-index-url https://azuremlsdktestpypi.azureedge.net/sdk-release/Preview/E7501C02541B433786111FE8E140CAA1\n",
    "    - azureml-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lstmscore.py file is python code defining the web service operation. It includes both the init() and run() functions defined earlier imports the required libraries. These should be nearly identical to the previous defined versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}score.py\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "TICKER = \"MSFT\"\n",
    "LSTM_MODEL = TICKER +'-modellstm.h5'\n",
    "MIN_MAX_DICT = TICKER +'-min_max.pkl'\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global min_max_dict_list\n",
    "    \n",
    "    # load model\n",
    "    model_path = Model.get_model_path(model_name = LSTM_MODEL)\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Load Min Max list values\n",
    "    model_path = Model.get_model_path(model_name = MIN_MAX_DICT)\n",
    "    with open(model_path, 'rb') as handle:\n",
    "        min_max_dict_list = pickle.load(handle)\n",
    "        print(\"Min_max List loaded\")\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = pd.read_json(data, orient='records')\n",
    "        data_n = data.copy()\n",
    "        \n",
    "        # Normalize data\n",
    "        min_dict = min_max_dict_list[0]\n",
    "        max_dict = min_max_dict_list[1]\n",
    "        for feature_name in data.columns:\n",
    "            data_n[feature_name] = (data[feature_name] - min_dict[feature_name]) / (max_dict[feature_name] - min_dict[feature_name])\n",
    "        \n",
    "        # Create sequences\n",
    "        data = data_n.values \n",
    "        seq_len = 10\n",
    "        result = []\n",
    "        for index in range(len(data) - seq_len + 1):\n",
    "            result.append(data[index: index + seq_len + 1])\n",
    "\n",
    "        result = np.array(result)\n",
    "        print(result.shape)\n",
    "        \n",
    "        pred = model.predict(result)\n",
    "        print(pred)\n",
    "        \n",
    "        # De-normalize the target\n",
    "        pred = pred * (max_dict[\"Close\"] - min_dict[\"Close\"]) + min_dict[\"Close\"]\n",
    "        \n",
    "        # Send results\n",
    "        pred = pred.tolist()\n",
    "        return json.dumps({\"result\": pred})\n",
    "\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also include a python file test_service.py which can test the web service you create. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/test_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}test_service.py\n",
    "\n",
    "import urllib\n",
    "import json \n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# The URL will need to be editted after service create.\n",
    "url = 'http://23.96.11.240:5001/score'\n",
    "\n",
    "## Sequence length will need to match the training sequence length from the model training\n",
    "sequence_length = 10\n",
    "\n",
    "# We'll read in this data to test the service\n",
    "body = pd.read_pickle('test_dataframe.pkl')\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "try:\n",
    "    if body.shape[0] < sequence_length : \n",
    "        print(\"Skipping scoring as we need {} records to score and only have {} records.\".format(sequence_length, body.shape[0]))\n",
    "    else:\n",
    "        #print('{}'.format(body.shape))\n",
    "        body = json.dumps({\"data\": body.to_json(orient='records')})\n",
    "        print (body + '\\n')\n",
    "        req = urllib.request.Request(url, str.encode(body), headers) \n",
    "        \n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            the_page = response.read()\n",
    "            print('{}'.format(the_page))\n",
    "        \n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code {}: \\n{}\".format(error, error.read))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.reason)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Docker on Linux\n",
    "\n",
    "> On a Linux DSVM, run the script below to configure Docker correctly. **Remember to log out and log back in after running the script.**\n",
    "\n",
    "```bash\n",
    "sudo /opt/microsoft/azureml/initial_setup.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a web service out of the scoring script\n",
    "\n",
    "Let's now see how we can create a scoring web service from the above model. We are going to be using the Preview of the Azure ML Python SDK.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download and install Azure ML Python SDK\n",
    "In a terminal window, type the following commands.\n",
    "  \n",
    "```shell\n",
    "# create a new conda environment with Python 3.6, numpy and cython\n",
    "$ conda create -n myenv Python=3.6 cython num\n",
    "\n",
    "# Activate the conde environment\n",
    "$ source activate myenv\n",
    "\n",
    "# check pip is pointing to the right pip path\n",
    "(myenv) $ pip --version\n",
    "# you should see a path that includes the name of the conda environment (myenv) such as:\n",
    "# <user-home-dir>/miniconda3/envs/myenv/lib/python3.6/site-packages (python 3.6)\n",
    "\n",
    "# install azure-cli\n",
    "(myenv) $ pip install azure-cli\n",
    "\n",
    "# install or update azureml meta-package\n",
    "(myenv) $ pip install --upgrade --extra-index-url https://azuremlsdktestpypi.azureedge.net/sdk-release/Preview/E7501C02541B433786111FE8E140CAA1 azureml-sdk\n",
    "\n",
    "# add myenv as a new Jupyter Kernel\n",
    "(myenv) $ python -m ipykernel install --user --name myenv --display-name \"myenv‚Äù\n",
    "\n",
    "# Now change the kernel on this notebook to myenv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Register the new RP (Azure Resource Provider)\n",
    "You also must register the new RP in your subscription:\n",
    "```shell\n",
    "$ az login\n",
    "$ az account set -s \"<subscription_id>\"\n",
    "\n",
    "# register the new RP\n",
    "$ az provider register -n Microsoft.MachineLearningServices\n",
    "\n",
    "# check the registration status\n",
    "$ az provider show -n Microsoft.MachineLearningServices\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configure the AML Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 0.1.0.1095338\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"b1395605-1fe9-4af4-b3ff-82a4725a3791\"\n",
    "resource_group = \"meetup_aml_rg\"\n",
    "workspace_name = \"meetup_aml_workspace\"\n",
    "workspace_region = 'eastus2' # or eastus2euap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The resource group doesn't exist or was not provided. AzureML SDK is creating a resource group=meetup_aml_rg in location=eastus2 using subscription=b1395605-1fe9-4af4-b3ff-82a4725a3791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourceGroups/meetup_aml_rg/providers/Microsoft.MachineLearningServices/workspaces/meetup_aml_workspace',\n",
       " 'name': 'meetup_aml_workspace',\n",
       " 'location': 'eastus2',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'description': '',\n",
       " 'friendlyName': 'meetup_aml_workspace',\n",
       " 'containerRegistry': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourcegroups/meetup_aml_rg/providers/microsoft.containerregistry/registries/meetupamacrptecrljo',\n",
       " 'keyVault': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourcegroups/meetup_aml_rg/providers/microsoft.keyvault/vaults/meetupamkeyvaultonhjrjbp',\n",
       " 'applicationInsights': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourcegroups/meetup_aml_rg/providers/microsoft.insights/components/meetupaminsightsokkbjkte',\n",
       " 'identityPrincipalId': '9db92e39-4f84-436d-b7d0-c9dd25766f54',\n",
       " 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'storageAccount': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourcegroups/meetup_aml_rg/providers/microsoft.storage/storageaccounts/meetupamstoragevbxotzpq'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the Workspace class and create the AML Workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region)\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: /home/sshuser/notebooks/Meetups-Data-AI-DFW/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "#You can validate that you have access to the specified workspace and write a configuration file \n",
    "#to the default configuration location, ./aml_config/config.json\n",
    "\n",
    "ws = Workspace(workspace_name = workspace_name,\n",
    "               subscription_id = subscription_id,\n",
    "               resource_group = resource_group)\n",
    "\n",
    "# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/sshuser/notebooks/Meetups-Data-AI-DFW/aml_config/config.json\n",
      "meetup_aml_workspace\n",
      "meetup_aml_rg\n",
      "eastus2\n",
      "b1395605-1fe9-4af4-b3ff-82a4725a3791\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuratio from ./aml_config/config.json file\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model MSFT-modellstm.h5\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = LSTM_MODEL_PATH,\n",
    "                       model_name = LSTM_MODEL,\n",
    "                       tags = [TICKER, \"Close\", \"lstm\"],\n",
    "                       description = \"LSTM regression model to predict \"+ TICKER +\" Close price\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model MSFT-min_max.pkl\n"
     ]
    }
   ],
   "source": [
    "min_max_dict_model = Model.register(model_path = MIN_MAX_DICT_PATH,\n",
    "                       model_name = MIN_MAX_DICT,\n",
    "                       tags = [TICKER, \"MinMaxDict\"],\n",
    "                       description = \"MIN_MAX dictionary use to normalization of \"+ TICKER +\" stock data\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT-min_max.pkl\tMIN_MAX dictionary use to normalization of MSFT stock data\t1\n"
     ]
    }
   ],
   "source": [
    "print(min_max_dict_model.name, min_max_dict_model.description, min_max_dict_model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore the registered models within your workspace and query by tag. Models are versioned. If you call the register_model command many times with same model name, you will get multiple versions of the model with increasing version numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: MSFT-min_max.pkl \tVersion: 1 \tDescription: MIN_MAX dictionary use to normalization of MSFT stock data ['MSFT', 'MinMaxDict']\n",
      "Name: MSFT-modellstm.h5 \tVersion: 1 \tDescription: LSTM regression model to predict MSFT Close price ['MSFT', 'Close', 'lstm']\n",
      "Name: MSFT-modellstm \tVersion: 1 \tDescription: LSTM regression model to predict MSFT price ['MSFT', 'regressionPrice', 'lstm']\n"
     ]
    }
   ],
   "source": [
    "regression_models = ws.models(tag = TICKER)\n",
    "for m in regression_models:\n",
    "    print(\"Name:\", m.name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that following command can take few minutes.<br>\n",
    "Note that the score.py and the conda yml file must be in the same directory than this notebook.<br>\n",
    "You can add tags and descriptions to images. Also, an image can contain multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./stockdemo-model/score.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./stockdemo-model/myenv.yml ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running..................................\n",
      "SucceededImage creation operation finished for image msft.image:3, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import Image\n",
    "image = Image.create(name = TICKER.lower() + \".image\",\n",
    "                     # this is the model object \n",
    "                     models = [model, min_max_dict_model],\n",
    "                     runtime = \"python\",\n",
    "                     execution_script = \"score.py\",\n",
    "                     conda_file = \"myenv.yml\",\n",
    "                     tags = [TICKER, \"Close\", \"lstm\"],\n",
    "                     description = \"Image with \"+ TICKER + \"regression LSTM model\",\n",
    "                     workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm score.py myenv.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msft.image(v.3 [Succeeded]) stored at meetupamacrptecrljo.azurecr.io/msft.image:3 with build log https://eastus2ice.blob.core.windows.net/logs/meetupamacrptecrljo15306109361596356.txt?sig=FPKAH8d6uz%2BiOc9rUBIxcAVEggab2sS6KyWKoWdlsIQ%3D&sr=b&sp=r&se=2018-08-02T09%3A45%3A12Z&sv=2017-04-17\n",
      "msft.image(v.2 [Succeeded]) stored at meetupamacrptecrljo.azurecr.io/msft.image:2 with build log https://eastus2ice.blob.core.windows.net/logs/meetupamacrptecrljo15306105079018524.txt?sp=r&sig=Rlpy9X%2BBX9UyOOUQhLXcgB0Sn/syzZmdJ2ylY1NSgwE%3D&se=2018-08-02T09%3A38%3A08Z&sr=b&sv=2017-04-17\n",
      "msft.image(v.1 [Succeeded]) stored at meetupamacrptecrljo.azurecr.io/msft.image:1 with build log https://eastus2ice.blob.core.windows.net/logs/meetupamacrptecrljo15306088028517042.txt?se=2018-08-02T09%3A11%3A04Z&sp=r&sv=2017-04-17&sr=b&sig=6cxnALzsttwmDpruibbi3Xl5C6OQDX5EzDAwicawLWk%3D\n"
     ]
    }
   ],
   "source": [
    "for i in Image.list(workspace = ws,tag = TICKER):\n",
    "    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deploy image as web service on Azure Container Instance\n",
    "\n",
    "Note that the service creation can take few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 4, \n",
    "                                               tags = [TICKER, \"Close\", \"lstm\"], \n",
    "                                               description = \"ACI Service to predict \"+ TICKER +\" Close price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msft-aciservice\n",
      "Creating service\n",
      "Running....................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = ACI_SERVICE_NAME.lower()\n",
    "print(aci_service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this command to debug if Service failed\n",
    "aci_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web service is hosted in ACI: http://23.96.11.240:5001/score\n"
     ]
    }
   ],
   "source": [
    "print('web service is hosted in ACI:', aci_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [[91.40367126464844]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_sample = json.dumps({\"data\": test_df.to_json(orient='records')})\n",
    "\n",
    "prediction = aci_service.run(input_data = test_sample)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can run the test_service.py on the terminal and should yield the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Delete web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
