{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB1 - Model Operationalization & Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run the below lab, make sure that you run the Part 3 lab: [Meetup10-Lab-stockdemo.ipynb](Meetup10-Lab-stockdemo.ipynb)\n",
    "\n",
    "In this notebook, we will create the artifacts and scripts to deploy the LSTM model into a webservice on Azure. The artifacts include the model files, and test scripts to validate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /data/anaconda/envs/py36/lib/python3.6/site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from h5py) (1.14.5)\n",
      "Requirement already satisfied: six in /data/anaconda/envs/py36/lib/python3.6/site-packages (from h5py) (1.11.0)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mazureml-contrib-brainwave 0.1.56 requires tensorflow>=1.6, which is not installed.\u001b[0m\n",
      "\u001b[31mazureml-train-widgets 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 0.1.59 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-core 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 0.1.59 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-sdk 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 0.1.59 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-pipeline-core 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 0.1.59 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-tensorboard 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 0.1.59 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-server 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 0.1.59 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-run 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 0.1.59 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-brainwave 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 0.1.59 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#This is only one time run to install the required python libraries on this virtual machine\n",
    "!{sys.executable} -m pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# import the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER = \"MSFT\"\n",
    "\n",
    "SHARE_ROOT = \"./stockdemo-model/\"\n",
    "\n",
    "# the model in h5 format\n",
    "LSTM_MODEL = TICKER +'-modellstm.h5'\n",
    "LSTM_MODEL_PATH = SHARE_ROOT + LSTM_MODEL\n",
    "\n",
    "# the min_max values dictionary\n",
    "MIN_MAX_DICT = TICKER +'-min_max.pkl'\n",
    "MIN_MAX_DICT_PATH = SHARE_ROOT + MIN_MAX_DICT\n",
    "\n",
    "# path to pickle test df\n",
    "TEST_DATA_PATH = SHARE_ROOT + TICKER + '-test_score_df.pkl'\n",
    "\n",
    "# Azure Container Service (ACI) Name\n",
    "ACI_SERVICE_NAME = TICKER + '-aciservice'\n",
    "\n",
    "# Azure Kubernetes Service (AKS) Name\n",
    "AKS_SERVICE_NAME = TICKER + '-aksservice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the test data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataframe loaded\n"
     ]
    }
   ],
   "source": [
    "with open(TEST_DATA_PATH, 'rb') as handle:\n",
    "    test_df = pickle.load(handle)\n",
    "    print(\"Test Dataframe loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-14</th>\n",
       "      <td>95.120</td>\n",
       "      <td>95.410</td>\n",
       "      <td>93.50</td>\n",
       "      <td>93.85</td>\n",
       "      <td>31576898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-15</th>\n",
       "      <td>93.530</td>\n",
       "      <td>94.580</td>\n",
       "      <td>92.83</td>\n",
       "      <td>94.18</td>\n",
       "      <td>26279014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16</th>\n",
       "      <td>94.680</td>\n",
       "      <td>95.380</td>\n",
       "      <td>93.92</td>\n",
       "      <td>94.60</td>\n",
       "      <td>47329521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-19</th>\n",
       "      <td>93.740</td>\n",
       "      <td>93.900</td>\n",
       "      <td>92.11</td>\n",
       "      <td>92.89</td>\n",
       "      <td>31752589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-20</th>\n",
       "      <td>93.050</td>\n",
       "      <td>93.770</td>\n",
       "      <td>93.00</td>\n",
       "      <td>93.13</td>\n",
       "      <td>21787780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-21</th>\n",
       "      <td>92.930</td>\n",
       "      <td>94.050</td>\n",
       "      <td>92.21</td>\n",
       "      <td>92.48</td>\n",
       "      <td>23753263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>91.265</td>\n",
       "      <td>91.750</td>\n",
       "      <td>89.66</td>\n",
       "      <td>89.79</td>\n",
       "      <td>37578166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>89.500</td>\n",
       "      <td>90.460</td>\n",
       "      <td>87.08</td>\n",
       "      <td>87.18</td>\n",
       "      <td>42159397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>90.610</td>\n",
       "      <td>94.000</td>\n",
       "      <td>90.40</td>\n",
       "      <td>93.78</td>\n",
       "      <td>55031149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>94.940</td>\n",
       "      <td>95.139</td>\n",
       "      <td>88.51</td>\n",
       "      <td>89.47</td>\n",
       "      <td>53704562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High    Low  Close      Volume\n",
       "Date                                                \n",
       "2018-03-14  95.120  95.410  93.50  93.85  31576898.0\n",
       "2018-03-15  93.530  94.580  92.83  94.18  26279014.0\n",
       "2018-03-16  94.680  95.380  93.92  94.60  47329521.0\n",
       "2018-03-19  93.740  93.900  92.11  92.89  31752589.0\n",
       "2018-03-20  93.050  93.770  93.00  93.13  21787780.0\n",
       "2018-03-21  92.930  94.050  92.21  92.48  23753263.0\n",
       "2018-03-22  91.265  91.750  89.66  89.79  37578166.0\n",
       "2018-03-23  89.500  90.460  87.08  87.18  42159397.0\n",
       "2018-03-26  90.610  94.000  90.40  93.78  55031149.0\n",
       "2018-03-27  94.940  95.139  88.51  89.47  53704562.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to recreate the feature engineering (creating the sequence features) just as we did in the model building notebook.\n",
    "\n",
    "We will do this within the webservice so that the service can take the raw  data, and return a scored result predicting the value (label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test init() and run() functions to read from the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web service requires two functions, an init() function that will initialize the web service by loading the model into the service, and a run() function that will engineer the features to match the model call structure, and score that data set. We create the functions in here for testing and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    # read in the model file\n",
    "    global model\n",
    "    global min_max_dict_list\n",
    "    \n",
    "    # load model\n",
    "    model = load_model(LSTM_MODEL_PATH)\n",
    "    print(\"Model Loaded\")\n",
    "    \n",
    "    # Load Min Max list values\n",
    "    with open(MIN_MAX_DICT_PATH, 'rb') as handle:\n",
    "        min_max_dict_list = pickle.load(handle)\n",
    "        print(\"Min_max List loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = pd.read_json(data, orient='records')\n",
    "        data_n = data.copy()\n",
    "        \n",
    "        # Normalize data\n",
    "        min_dict = min_max_dict_list[0]\n",
    "        max_dict = min_max_dict_list[1]\n",
    "        for feature_name in data_n.columns:\n",
    "            data_n[feature_name] = (data[feature_name] - min_dict[feature_name]) / (max_dict[feature_name] - min_dict[feature_name])\n",
    "        \n",
    "        # Create sequences\n",
    "        data_n = data_n.reindex(sorted(data_n.columns), axis=1) # To make sure columns are always with same order\n",
    "        data = data_n.values \n",
    "        seq_len = 10\n",
    "        result = []\n",
    "        for index in range(len(data) - seq_len + 1):\n",
    "            result.append(data[index: index + seq_len])\n",
    "\n",
    "        result = np.array(result)\n",
    "        print(result.shape)\n",
    "        \n",
    "        pred = model.predict(result)\n",
    "        print(pred)\n",
    "        \n",
    "        # de-normalize the target\n",
    "        pred = pred * (max_dict[\"Close\"] - min_dict[\"Close\"]) + min_dict[\"Close\"]\n",
    "        \n",
    "        # Send results\n",
    "        pred = pred.tolist()\n",
    "        return json.dumps({\"result\": pred})\n",
    "\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The webservice test requires an initialize of the webservice, then send the entire scoring data set into the model. We expect to get 1  prediction for each input in the scoring data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": \"[{\\\\\"Open\\\\\":95.12,\\\\\"High\\\\\":95.41,\\\\\"Low\\\\\":93.5,\\\\\"Close\\\\\":93.85,\\\\\"Volume\\\\\":31576898.0},{\\\\\"Open\\\\\":93.53,\\\\\"High\\\\\":94.58,\\\\\"Low\\\\\":92.83,\\\\\"Close\\\\\":94.18,\\\\\"Volume\\\\\":26279014.0},{\\\\\"Open\\\\\":94.68,\\\\\"High\\\\\":95.38,\\\\\"Low\\\\\":93.92,\\\\\"Close\\\\\":94.6,\\\\\"Volume\\\\\":47329521.0},{\\\\\"Open\\\\\":93.74,\\\\\"High\\\\\":93.9,\\\\\"Low\\\\\":92.11,\\\\\"Close\\\\\":92.89,\\\\\"Volume\\\\\":31752589.0},{\\\\\"Open\\\\\":93.05,\\\\\"High\\\\\":93.77,\\\\\"Low\\\\\":93.0,\\\\\"Close\\\\\":93.13,\\\\\"Volume\\\\\":21787780.0},{\\\\\"Open\\\\\":92.93,\\\\\"High\\\\\":94.05,\\\\\"Low\\\\\":92.21,\\\\\"Close\\\\\":92.48,\\\\\"Volume\\\\\":23753263.0},{\\\\\"Open\\\\\":91.265,\\\\\"High\\\\\":91.75,\\\\\"Low\\\\\":89.66,\\\\\"Close\\\\\":89.79,\\\\\"Volume\\\\\":37578166.0},{\\\\\"Open\\\\\":89.5,\\\\\"High\\\\\":90.46,\\\\\"Low\\\\\":87.08,\\\\\"Close\\\\\":87.18,\\\\\"Volume\\\\\":42159397.0},{\\\\\"Open\\\\\":90.61,\\\\\"High\\\\\":94.0,\\\\\"Low\\\\\":90.4,\\\\\"Close\\\\\":93.78,\\\\\"Volume\\\\\":55031149.0},{\\\\\"Open\\\\\":94.94,\\\\\"High\\\\\":95.139,\\\\\"Low\\\\\":88.51,\\\\\"Close\\\\\":89.47,\\\\\"Volume\\\\\":53704562.0}]\"}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps({\"data\": test_df.to_json(orient='records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n",
      "Min_max List loaded\n",
      "(1, 10, 5)\n",
      "[[0.7128389]]\n",
      "{\"result\": [[87.43899536132812]]}\n"
     ]
    }
   ],
   "source": [
    "init()\n",
    "pred=run(json.dumps({\"data\": test_df.to_json(orient='records')}))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we persist the assets we have created for use in operationalization. The conda dependencies are defined in this YAML file. This will be used to tell the webservice server which python packages are required to run this web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/myenv.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}myenv.yml\n",
    "name: myenv\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.5.2\n",
    "  - pip:\n",
    "    - keras\n",
    "    - tensorflow\n",
    "    - h5py\n",
    "    # Required packages for AzureML execution, history, and data preparation.\n",
    "    - azureml-sdk\n",
    "    - azureml-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score.py file is python code defining the web service operation. It includes both the init() and run() functions defined earlier imports the required libraries. These should be nearly identical to the previous defined versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}score.py\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "TICKER = \"MSFT\"\n",
    "LSTM_MODEL = TICKER +'-modellstm.h5'\n",
    "MIN_MAX_DICT = TICKER +'-min_max.pkl'\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global min_max_dict_list\n",
    "    \n",
    "    # load model\n",
    "    model_path = Model.get_model_path(model_name = LSTM_MODEL)\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Load Min Max list values\n",
    "    model_path = Model.get_model_path(model_name = MIN_MAX_DICT)\n",
    "    with open(model_path, 'rb') as handle:\n",
    "        min_max_dict_list = pickle.load(handle)\n",
    "        print(\"Min_max List loaded\")\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = pd.read_json(data, orient='records')\n",
    "        data_n = data.copy()\n",
    "        \n",
    "        # Normalize data\n",
    "        min_dict = min_max_dict_list[0]\n",
    "        max_dict = min_max_dict_list[1]\n",
    "        for feature_name in data.columns:\n",
    "            data_n[feature_name] = (data[feature_name] - min_dict[feature_name]) / (max_dict[feature_name] - min_dict[feature_name])\n",
    "        \n",
    "        # Create sequences\n",
    "        data_n = data_n.reindex(sorted(data_n.columns), axis=1) # To make sure columns are always with same order\n",
    "        data = data_n.values \n",
    "        seq_len = 10\n",
    "        result = []\n",
    "        for index in range(len(data) - seq_len + 1):\n",
    "            result.append(data[index: index + seq_len])\n",
    "\n",
    "        result = np.array(result)\n",
    "        print(result.shape)\n",
    "        \n",
    "        pred = model.predict(result)\n",
    "        print(pred)\n",
    "        \n",
    "        # De-normalize the target\n",
    "        pred = pred * (max_dict[\"Close\"] - min_dict[\"Close\"]) + min_dict[\"Close\"]\n",
    "        \n",
    "        # Send results\n",
    "        pred = pred.tolist()\n",
    "        return json.dumps({\"result\": pred})\n",
    "\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also include a python file test_service.py which can test the web service you create. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a web service out of the scoring script\n",
    "\n",
    "Let's now see how we can create a scoring web service from the above model. We are going to be using the Preview of the Azure ML Python SDK.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Optional - If not on DSVM or Azure notebooks - Download and install Azure ML Python SDK\n",
    "In a terminal window, type the following commands.\n",
    "  \n",
    "```shell\n",
    "# create a new conda environment with Python 3.6, numpy and cython\n",
    "$ conda create -n myenv Python=3.6 cython numpy\n",
    "\n",
    "# Activate the conde environment\n",
    "$ source activate myenv\n",
    "\n",
    "# check pip is pointing to the right pip path\n",
    "(myenv) $ pip --version\n",
    "# you should see a path that includes the name of the conda environment (myenv) such as:\n",
    "# <user-home-dir>/miniconda3/envs/myenv/lib/python3.6/site-packages (python 3.6)\n",
    "\n",
    "# install azure-cli\n",
    "(myenv) $ pip install azure-cli\n",
    "\n",
    "# install or update azureml meta-package\n",
    "(myenv) $ pip install azureml-sdk[notebooks]\n",
    "\n",
    "\n",
    "# add myenv as a new Jupyter Kernel\n",
    "(myenv) $ python -m ipykernel install --user --name myenv --display-name \"myenv\"\n",
    "\n",
    "# Now change the kernel on this notebook to myenv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Register the new RP (Azure Resource Provider)\n",
    "You also must register the new RP in your subscription:\n",
    "```shell\n",
    "$ az login\n",
    "$ az account set -s \"<subscription_id>\"\n",
    "\n",
    "# register the new RP\n",
    "$ az provider register -n Microsoft.MachineLearningServices\n",
    "\n",
    "# check the registration status\n",
    "$ az provider show -n Microsoft.MachineLearningServices\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configure the AML Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 0.1.59\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Workspace class and create the AML Workspace\n",
    "\n",
    "from azureml.core import Workspace\n",
    "subscription_id = \"b1395605-1fe9-4af4-b3ff-82a4725a3791\"\n",
    "resource_group = \"meetups_aml_rg\"\n",
    "workspace_name = \"meetups_aml_workspace\"\n",
    "workspace_region = 'eastus2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only one time\n",
    "# ws = Workspace.create(name = workspace_name,\n",
    "#                       subscription_id = subscription_id,\n",
    "#                       resource_group = resource_group, \n",
    "#                       location = workspace_region)\n",
    "# ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fail to load or parse file /home/sshuser/.azure/azureProfile.json. It is overridden by default settings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fail to load or parse file /home/sshuser/.azure/azureProfile.json. It is overridden by default settings.\n",
      "Fail to load or parse file /home/sshuser/.azure/az.json. It is overridden by default settings.\n",
      "Fail to load or parse file /home/sshuser/.azure/az.sess. It is overridden by default settings.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code BYUE35JZZ to authenticate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n",
      "Wrote the config file config.json to: /data/home/sshuser/notebooks/Meetups-Data-AI-DFW/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "#You can validate that you have access to the specified workspace and write a configuration file \n",
    "#to the default configuration location, ./aml_config/config.json\n",
    "\n",
    "ws = Workspace(workspace_name = workspace_name,\n",
    "               subscription_id = subscription_id,\n",
    "               resource_group = resource_group)\n",
    "\n",
    "# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/sshuser/notebooks/Meetups-Data-AI-DFW/aml_config/config.json\n",
      "meetups_aml_workspace\n",
      "meetups_aml_rg\n",
      "eastus2\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuratio from ./aml_config/config.json file\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link (Preview whitelisted) to see the portal UI\n",
    "\n",
    "https://aka.ms/mlextensions_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model MSFT-modellstm.h5\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = LSTM_MODEL_PATH,\n",
    "                       model_name = LSTM_MODEL,\n",
    "                       tags = {'ticker': TICKER, 'type': \"lstm\", 'target': \"Close\"},\n",
    "                       description = \"LSTM regression model to predict \"+ TICKER +\" Close price\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model MSFT-min_max.pkl\n"
     ]
    }
   ],
   "source": [
    "min_max_dict_model = Model.register(model_path = MIN_MAX_DICT_PATH,\n",
    "                       model_name = MIN_MAX_DICT,\n",
    "                       tags = {'ticker': TICKER, 'type': \"pickleDict\", 'target': \"Close\"},\n",
    "                       description = \"MIN_MAX dictionary use to normalization of \"+ TICKER +\" stock data\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT-min_max.pkl\tMIN_MAX dictionary use to normalization of MSFT stock data\t6\n"
     ]
    }
   ],
   "source": [
    "print(min_max_dict_model.name, min_max_dict_model.description, min_max_dict_model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore the registered models within your workspace and query by tag. Models are versioned. If you call the register_model command many times with same model name, you will get multiple versions of the model with increasing version numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: MSFT-modellstm.h5 \tVersion: 6\n",
      "Name: MSFT-modellstm.h5 \tVersion: 5\n",
      "Name: MSFT-modellstm.h5 \tVersion: 4\n",
      "Name: MSFT-modellstm.h5 \tVersion: 3\n",
      "Name: MSFT-modellstm.h5 \tVersion: 2\n",
      "Name: MSFT-modellstm.h5 \tVersion: 1\n"
     ]
    }
   ],
   "source": [
    "for m in ws.models(name=LSTM_MODEL):\n",
    "    print(\"Name:\", m.name,\"\\tVersion:\", m.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that following command can take few minutes.<br>\n",
    "Note that the score.py and the conda yml file must be in the same directory than this notebook.<br>\n",
    "You can add tags and descriptions to images. Also, an image can contain multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./stockdemo-model/score.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./stockdemo-model/myenv.yml ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running............................\n",
      "SucceededImage creation operation finished for image msft.image:6, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  description = \"Image with \"+ TICKER + \"regression LSTM model\",\n",
    "                                                  tags = {'ticker': TICKER, 'type': \"lstm\", 'target': \"Close\"}\n",
    "                                                 )\n",
    "\n",
    "image = ContainerImage.create(name = TICKER.lower() + \".image\",\n",
    "                              # this is the model object\n",
    "                              models = [model, min_max_dict_model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm score.py myenv.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msft.image:6 msft.image(v.6 [Succeeded]) stored at meetupsaacrevoriscu.azurecr.io/msft.image:6 with build log https://eastus2ice.blob.core.windows.net/logs/meetupsaacrevoriscu_ae6d420571f74f3292dc3459827e1c10.txt?sp=r&sr=b&sv=2017-04-17&se=2018-10-28T05%3A43%3A37Z&sig=pp2MMlnL/Zk0F%2BPbcguiT1snC80K8W5vn3N%2B%2B2oZ48w%3D\n",
      "msft.image:5 msft.image(v.5 [Succeeded]) stored at meetupsaacrevoriscu.azurecr.io/msft.image:5 with build log https://eastus2ice.blob.core.windows.net/logs/meetupsaacrevoriscu_bc57fbde33fa41f99592707c9267d0f0.txt?sv=2017-04-17&sr=b&sig=uqdAvOalTqmD7yJP7Uu6Wn2eCNXXrBKcG2xX7z23qEM%3D&sp=r&se=2018-10-19T20%3A49%3A11Z\n",
      "msft.image:4 msft.image(v.4 [Succeeded]) stored at meetupsaacrevoriscu.azurecr.io/msft.image:4 with build log https://eastus2ice.blob.core.windows.net/logs/meetupsaacrevoriscu_0552b96b48ef41e79e2970f3ed3af4e3.txt?sr=b&sp=r&se=2018-10-19T18%3A21%3A44Z&sig=PqDV9K4CoYVPEiu84Jca0%2Bgt99H52yEZj9s/46cdzO4%3D&sv=2017-04-17\n",
      "msft.image:3 msft.image(v.3 [Succeeded]) stored at meetupsaacrevoriscu.azurecr.io/msft.image:3 with build log https://eastus2ice.blob.core.windows.net/logs/meetupsaacrevoriscu_a53d8bc3f18d4c8baebe36ebb0212724.txt?sr=b&sp=r&se=2018-10-18T20%3A17%3A33Z&sig=vv180EPGZeK%2B%2BtEcnjwnAdP6/brjAidTgE2mf8ByFrA%3D&sv=2017-04-17\n",
      "msft.image:2 msft.image(v.2 [Succeeded]) stored at meetupsaacrevoriscu.azurecr.io/msft.image:2 with build log https://eastus2ice.blob.core.windows.net/logs/meetupsaacrevoriscu_d9114da200d141cab04a6ef885aeaf29.txt?sr=b&sp=r&se=2018-10-18T09%3A04%3A42Z&sig=y598qYD1pPMaeO52jSvWrql7gishwaFS0RNJkK2L1zA%3D&sv=2017-04-17\n",
      "msft.image:1 msft.image(v.1 [Succeeded]) stored at meetupsaacrevoriscu.azurecr.io/msft.image:1 with build log https://eastus2ice.blob.core.windows.net/logs/meetupsaacrevoriscu_2835ec5925a4477a992e6089083e0029.txt?sr=b&sv=2017-04-17&se=2018-10-10T06%3A57%3A42Z&sig=RzI2UedtNp8jyhDVRPEhtPOMEQjvdcoQbOs82Ezt3ss%3D&sp=r\n"
     ]
    }
   ],
   "source": [
    "for i in image.list(workspace = ws, image_name=TICKER.lower() + \".image\"):\n",
    "    print('{} {}(v.{} [{}]) stored at {} with build log {}'.format(i.id, i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deploy image as web service on Azure Container Instance (ACI)\n",
    "\n",
    "Note that the service creation can take few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 4, \n",
    "                                               tags = {'ticker': TICKER, 'type': \"lstm\", 'target': \"Close\"}, \n",
    "                                               description = \"ACI Service to predict \"+ TICKER +\" Close price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msft-aciservice\n",
      "Creating service\n",
      "Running.......................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 702 ms, sys: 67.7 ms, total: 770 ms\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = ACI_SERVICE_NAME.lower()\n",
    "print(aci_service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this command to debug if Service failed\n",
    "#aci_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test ACI web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web service hosted in ACI: http://23.96.56.78:80/score\n"
     ]
    }
   ],
   "source": [
    "print('web service hosted in ACI:', aci_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [[87.43900299072266]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_sample = json.dumps({\"data\": test_df.to_json(orient='records')})\n",
    "\n",
    "prediction = aci_service.run(input_data = test_sample)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we manually create the json url payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"{\\\\\"result\\\\\": [[87.43900299072266]]}\"'\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# The URL will need to be editted after service create.\n",
    "url_aci = \"http://23.96.56.78:80/score\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "body = json.dumps({\"data\": test_df.to_json(orient='records')})\n",
    "\n",
    "#Send Request to ACI service and print response\n",
    "req_aci = urllib.request.Request(url_aci, str.encode(body), headers) \n",
    "print(urllib.request.urlopen(req_aci).read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can run the test_service.py on the terminal and should yield the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Deploy image as web service on Azure Kubernetes  (AKS)\n",
    "You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function provisioning_configuration in module azureml.core.compute.aks:\n",
      "\n",
      "provisioning_configuration(agent_count=None, vm_size=None, ssl_cname=None, ssl_cert_pem_file=None, ssl_key_pem_file=None, location=None)\n",
      "    Create a configuration object for provisioning an AKS compute target\n",
      "    \n",
      "    :param agent_count: Number of agents (VMs) to host containers\n",
      "    :type agent_count: int\n",
      "    :param vm_size: Size of agent VMs. A full list of options can be found here: https://aka.ms/azureml-aks-details\n",
      "    :type vm_size: str\n",
      "    :param ssl_cname: A CName to use if enabling SSL validation on the cluster. Must provide all three\n",
      "        CName, cert file, and key file to enable SSL validation\n",
      "    :type ssl_cname: str\n",
      "    :param ssl_cert_pem_file: A file path to a file containing cert information for SSL validation. Must provide\n",
      "        all three CName, cert file, and key file to enable SSL validation\n",
      "    :type ssl_cert_pem_file: str\n",
      "    :param ssl_key_pem_file: A file path to a file containing key information for SSL validation. Must provide\n",
      "        all three CName, cert file, and key file to enable SSL validation\n",
      "    :type ssl_key_pem_file: str\n",
      "    :param location: Location to provision cluster in. If not specified, will default to workspace location.\n",
      "        Available regions for this compute can be found here:\n",
      "        https://azure.microsoft.com/en-us/global-infrastructure/services/?regions=all&products=kubernetes-service\n",
      "    :type location: str\n",
      "    :return: A configuration object to be used when creating a Compute object\n",
      "    :rtype: AksProvisioningConfiguration\n",
      "    :raises: ComputeTargetException\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "help(AksCompute.provisioning_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating..........................................................................................................................................................................................\n",
      "SucceededAKS provisioning operation finished, operation \"Succeeded\"\n",
      "None\n",
      "CPU times: user 2.43 s, sys: 302 ms, total: 2.74 s\n",
      "Wall time: 16min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use the default configuration (can also provide parameters to customize)\n",
    "prov_config = AksCompute.provisioning_configuration(agent_count=5, vm_size=\"Standard_DS2_v2\", ssl_cname=None, \n",
    "                                                    ssl_cert_pem_file=None, ssl_key_pem_file=None, \n",
    "                                                    location=\"EastUs2\")\n",
    "\n",
    "aks_name = 'meetup-aks'\n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                 name = aks_name, \n",
    "                                 provisioning_configuration = prov_config)\n",
    "\n",
    "aks_target.wait_for_completion(show_output = True)\n",
    "\n",
    "print(aks_target.provisioning_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating.\n",
      "FailedProvisioning operation finished, operation \"Failed\"\n",
      "Async operation failed with\n",
      "StatusCode: 404\n",
      "Message: The specified resource was not found\n",
      "Compute object has provisioning state \"Failed\"\n",
      "and provisioning errors: [{'error': {'code': 'NotFound', 'statusCode': 404, 'message': 'The specified resource was not found'}}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #Optional\n",
    "# #If you have existing AKS cluster in your Azure subscription, you can attach it to the Workspace.\n",
    "resource_id = '/subscriptions/'+subscription_id+'/resourcegroups/'+resource_group+'/providers/Microsoft.ContainerService/managedClusters/meetup-aks0cc0670632458d8'\n",
    "\n",
    "create_name='existing-aks' \n",
    "# # Create the cluster\n",
    "aks_target = AksCompute.attach(workspace=ws, name=create_name, resource_id=resource_id)\n",
    "# # Wait for the operation to complete\n",
    "aks_target.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: existing-aks\n",
      "Agent Count: 3\n",
      "VM Size: Standard_DS2_v2\n",
      "Location: eastus2\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:\", aks_target.name)\n",
    "print(\"Agent Count:\", aks_target.agent_count)\n",
    "print(\"VM Size:\", aks_target.agent_vm_size)\n",
    "print(\"Location:\", aks_target.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running...........\n",
      "SucceededAKS service creation operation finished, operation \"Succeeded\"\n",
      "{'desiredReplicas': 3, 'updatedReplicas': 3, 'availableReplicas': 3}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "#Set the web service configuration (using default here)\n",
    "aks_config = AksWebservice.deploy_configuration(autoscale_enabled=True, autoscale_min_replicas=3, \n",
    "                                                autoscale_max_replicas=10, autoscale_refresh_seconds=None, \n",
    "                                                autoscale_target_utilization=80, collect_model_data=None, \n",
    "                                                cpu_cores=None, memory_gb=None, enable_app_insights=True, \n",
    "                                                scoring_timeout_ms=None, replica_max_concurrent_requests=None, \n",
    "                                                num_replicas=None, primary_key=None, secondary_key=None, \n",
    "                                                tags = {'ticker': TICKER, 'type': \"lstm\", 'target': \"Close\"}, \n",
    "                                                description=\"AKS Service\")\n",
    "\n",
    "aks_service_name = AKS_SERVICE_NAME.lower() \n",
    "\n",
    "aks_service = Webservice.deploy_from_image(workspace = ws, \n",
    "                                           name = aks_service_name,\n",
    "                                           image = image,\n",
    "                                           deployment_config = aks_config,\n",
    "                                           deployment_target = aks_target)\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing-aks\n",
      "AKS\n",
      "http://40.117.134.109/api/v1/service/msft-aksservice/score\n",
      "{'desiredReplicas': 3, 'updatedReplicas': 3, 'availableReplicas': 3}\n",
      "10\n",
      "JMxJLbPpVL0eh7rGBeJjNRfUSrl4rbjU\n"
     ]
    }
   ],
   "source": [
    "print(aks_service.compute_name)\n",
    "print(aks_service.compute_type)\n",
    "print(aks_service.scoring_uri)\n",
    "print(aks_service.state)\n",
    "print(aks_service.max_concurrent_requests_per_container)\n",
    "print(aks_service.get_keys()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Test AKS web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web service hosted in AKS: http://40.117.134.109/api/v1/service/msft-aksservice/score\n"
     ]
    }
   ],
   "source": [
    "print('web service hosted in AKS:', aks_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [[87.43900299072266]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_sample = json.dumps({\"data\": test_df.to_json(orient='records')})\n",
    "\n",
    "prediction = aks_service.run(input_data = test_sample)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we manually create the json url payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"{\\\\\"result\\\\\": [[87.43900299072266]]}\"'\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import requests\n",
    "\n",
    "# The URL will need to be editted after service create.\n",
    "url_aks = aks_service.scoring_uri\n",
    "\n",
    "headers = {'Content-Type':'application/json', \"Authorization\":\"Bearer \"+aks_service.get_keys()[0]}\n",
    "\n",
    "body = json.dumps({\"data\": test_df.to_json(orient='records')})\n",
    "\n",
    "#Send Request to AKS service and print response\n",
    "req_aks = urllib.request.Request(url_aks, str.encode(body), headers) \n",
    "print(urllib.request.urlopen(req_aks).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Delete web services, image and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "aci_service.delete()\n",
    "aks_service.delete()\n",
    "image.delete()\n",
    "model.delete()\n",
    "min_max_dict_model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting\n",
      "Deleting\n"
     ]
    }
   ],
   "source": [
    "print(aks_service.state)\n",
    "print(aci_service.state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
